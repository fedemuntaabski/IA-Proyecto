"""
Air Draw Classifier - Aplicaci√≥n Principal

Aplicaci√≥n completa para clasificaci√≥n de dibujos en el aire que integra:
- Activaci√≥n de c√°mara del dispositivo
- Detecci√≥n de movimientos de manos en tiempo real
- Interpretaci√≥n de movimientos como trazos/dibujos
- Clasificaci√≥n autom√°tica de figuras dibujadas

Esta aplicaci√≥n reutiliza componentes avanzados del proyecto para ofrecer
una experiencia completa de dibujo en el aire con IA.
"""

import cv2
import numpy as np
import time
from pathlib import Path
from typing import List, Optional

# Importar componentes existentes
import sys
sys.path.insert(0, str(Path(__file__).parent))

from src.core.hand_detector import HandDetector
from src.core.gesture_processor import GestureProcessor
from src.core.classifier import SketchClassifier
from src.core.config_manager import ConfigManager


class AirDrawClassifier:
    """
    Aplicaci√≥n principal para clasificaci√≥n de dibujos en el aire.

    Esta clase integra todos los componentes del proyecto en una aplicaci√≥n
    completa y f√°cil de usar para dibujo en el aire con clasificaci√≥n IA.
    """

    def __init__(self, model_path: str = "IA/sketch_classifier_model.keras",
                 model_info_path: str = "IA/model_info.json"):
        """
        Inicializa la mini-app.

        Args:
            model_path: Ruta al modelo de clasificaci√≥n
            model_info_path: Ruta a la informaci√≥n del modelo
        """
        print("üöÄ Iniciando Mini Air Draw Classifier...")
        print("=" * 50)

        # Inicializar configuraci√≥n
        self.config_manager = ConfigManager()
        self.detection_config = self.config_manager.get_detection_config()
        self.ml_config = self.config_manager.get_ml_config()

        # Inicializar componentes principales
        self.hand_detector = HandDetector(min_area=5000, max_area=50000)
        self.gesture_processor = GestureProcessor(image_size=28)
        self.classifier = SketchClassifier(model_path, model_info_path, enable_fallback=True)

        # Estado de la aplicaci√≥n
        self.is_drawing = False
        self.last_prediction = None
        self.drawing_start_time = None
        self.session_start_time = time.time()
        self.total_drawings = 0
        self.successful_predictions = 0

        # Configuraci√≥n simplificada
        self.min_points_for_classification = 10  # M√≠nimo puntos para intentar clasificar
        self.classification_cooldown = 2.0  # Segundos entre clasificaciones
        self.confidence_threshold = self.ml_config.confidence_threshold

        print("‚úì Componentes inicializados")
        print(f"  Detector de manos: {'Avanzado' if self.hand_detector.enable_advanced_vision else 'B√°sico'}")
        print(f"  Clasificador: {'Disponible' if self.classifier.is_available() else 'No disponible'}")
        print()

    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        """
        Procesa un frame de la c√°mara.

        Args:
            frame: Frame de OpenCV (BGR)

        Returns:
            Frame procesado con visualizaciones
        """
        # Voltear para efecto espejo
        frame = cv2.flip(frame, 1)
        height, width = frame.shape[:2]

        # Detectar manos
        frame_rgb, contours, has_hands = self.hand_detector.detect(frame)

        # Procesar si hay manos
        if has_hands and contours:
            # Obtener posici√≥n del dedo √≠ndice
            index_pos = self.hand_detector.get_index_finger_tip(contours)

            if index_pos and self.hand_detector.is_drawing_gesture(contours):
                # Usuario est√° dibujando
                if not self.is_drawing:
                    self.is_drawing = True
                    self.drawing_start_time = time.time()
                    self.gesture_processor.clear()
                    print("‚úèÔ∏è  Comenzando dibujo...")

                # Agregar punto al gesto
                normalized_pos = (index_pos[0] / width, index_pos[1] / height)
                self.gesture_processor.add_point(normalized_pos, (height, width))
            else:
                # Usuario dej√≥ de dibujar
                if self.is_drawing:
                    self.is_drawing = False
                    points_count = len(self.gesture_processor.stroke_points)

                    if points_count >= self.min_points_for_classification:
                        self._classify_current_gesture()
                    else:
                        print(f"‚ö† Dibujo muy corto ({points_count} puntos)")

        # Crear frame de visualizaci√≥n
        display_frame = frame.copy()

        # Dibujar contornos si hay manos
        if has_hands and contours:
            display_frame = self.hand_detector.draw_landmarks(display_frame, contours)

        # Dibujar trazo actual
        if len(self.gesture_processor.stroke_points) > 0:
            display_frame = self.gesture_processor.draw_on_frame(
                display_frame,
                frame_shape=(height, width)
            )

        # Interfaz simplificada
        self._draw_simple_ui(display_frame, has_hands, contours)

        return display_frame

    def _classify_current_gesture(self):
        """Clasifica el gesto actual si es posible."""
        if len(self.gesture_processor.stroke_points) < self.min_points_for_classification:
            return

        print("üîç Clasificando dibujo...")
        self.total_drawings += 1

        # Obtener imagen del gesto
        gesture_image = self.gesture_processor.get_gesture_image()

        if gesture_image is None:
            print("‚ö† No se pudo procesar el gesto")
            return

        # Realizar clasificaci√≥n
        if self.classifier.is_available():
            predictions = self.classifier.predict(gesture_image, top_k=3)

            if predictions:
                top_class, confidence = predictions[0]
                self.last_prediction = (top_class, confidence, time.time())

                # Contar predicci√≥n exitosa si supera el umbral
                if confidence >= self.confidence_threshold:
                    self.successful_predictions += 1

                print(f"üéØ Predicci√≥n: {top_class} ({confidence:.1%})")

                if len(predictions) > 1:
                    print("  Otras opciones:")
                    for alt_class, alt_conf in predictions[1:2]:  # Solo mostrar la segunda mejor
                        print(f"    {alt_class} ({alt_conf:.1%})")
            else:
                print("‚ö† No se obtuvieron predicciones")
        else:
            print("‚ö† Clasificador no disponible")

        print()

    def _show_session_stats(self):
        """Muestra estad√≠sticas de la sesi√≥n actual."""
        session_duration = time.time() - self.session_start_time
        success_rate = (self.successful_predictions / self.total_drawings * 100) if self.total_drawings > 0 else 0

        print("\n" + "="*50)
        print("üìä ESTAD√çSTICAS DE LA SESI√ìN")
        print("="*50)
        print(f"‚è±Ô∏è  Duraci√≥n: {session_duration:.1f} segundos")
        print(f"üé® Dibujos realizados: {self.total_drawings}")
        print(f"‚úÖ Predicciones exitosas: {self.successful_predictions}")
        print(f"üìà Tasa de √©xito: {success_rate:.1f}%")
        print(f"ü§ñ Modo clasificador: {self.classifier.mode.upper()}")
        print("="*50)

    def _draw_simple_ui(self, frame: np.ndarray, has_hands: bool, contours: List):
        """
        Dibuja una interfaz de usuario simplificada.

        Args:
            frame: Frame donde dibujar
            has_hands: Si se detectaron manos
            contours: Contornos detectados
        """
        height, width = frame.shape[:2]

        # Barra superior con informaci√≥n b√°sica
        cv2.rectangle(frame, (0, 0), (width, 60), (30, 30, 30), -1)
        cv2.rectangle(frame, (0, 0), (width, 60), (200, 200, 200), 1)

        # Estado de detecci√≥n
        if has_hands and contours:
            status_text = f"üëã Mano detectada | Puntos: {len(self.gesture_processor.stroke_points)}"
            status_color = (0, 255, 0)
        else:
            status_text = "Sin detecci√≥n de manos"
            status_color = (0, 0, 255)

        cv2.putText(frame, status_text, (10, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 2)

        # Estado de dibujo
        if self.is_drawing:
            draw_status = "‚úèÔ∏è DIBUJANDO..."
            draw_color = (0, 255, 255)
        else:
            draw_status = "Listo para dibujar"
            draw_color = (255, 165, 0)

        cv2.putText(frame, draw_status, (10, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, draw_color, 2)

        # Mostrar √∫ltima predicci√≥n si existe y no ha expirado
        if self.last_prediction:
            class_name, confidence, pred_time = self.last_prediction
            if time.time() - pred_time < 5.0:  # Mostrar por 5 segundos
                pred_text = f"üéØ {class_name} ({confidence:.0%})"
                cv2.putText(frame, pred_text, (width - 250, 40),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # Controles en la parte inferior
        controls_y = height - 40
        cv2.rectangle(frame, (0, controls_y), (width, height), (20, 20, 20), -1)
        cv2.rectangle(frame, (0, controls_y), (width, height), (150, 150, 150), 1)

        controls_text = "CONTROLES: [ESPACIO] Nueva clasificaci√≥n | [R] Limpiar | [Q] Salir"
        cv2.putText(frame, controls_text, (10, height - 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

    def run(self):
        """Ejecuta el loop principal de la mini-app."""
        print("üìπ Iniciando c√°mara...")
        cap = cv2.VideoCapture(0)

        if not cap.isOpened():
            print("‚ùå Error: No se pudo acceder a la c√°mara")
            return

        # Configurar resoluci√≥n
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        print("‚úÖ C√°mara inicializada")
        print("\nüéÆ Controles:")
        print("  ESPACIO: Forzar nueva clasificaci√≥n")
        print("  R: Limpiar dibujo actual")
        print("  Q: Salir")
        print("\nüí° Instrucciones:")
        print("  1. Muestra tu mano a la c√°mara")
        print("  2. Dibuja una figura en el aire con el dedo √≠ndice")
        print("  3. La app intentar√° adivinar qu√© dibujaste")
        print("\n" + "=" * 50)

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # Procesar frame
                display_frame = self.process_frame(frame)

                # Mostrar frame
                cv2.imshow('Air Draw Classifier - IA Proyecto', display_frame)

                # Procesar teclas
                key = cv2.waitKey(1) & 0xFF

                if key == ord('q'):
                    print("\nüëã Saliendo...")
                    break
                elif key == ord('r'):
                    print("üßπ Limpiando dibujo...")
                    self.gesture_processor.clear()
                    self.last_prediction = None
                    self.is_drawing = False
                elif key == ord(' ') and len(self.gesture_processor.stroke_points) > 0:
                    # Forzar clasificaci√≥n
                    print("üîÑ Forzando clasificaci√≥n...")
                    self._classify_current_gesture()

        finally:
            cap.release()
            cv2.destroyAllWindows()
            self.hand_detector.close()
            self._show_session_stats()
            print("‚úÖ Aplicaci√≥n cerrada correctamente")

    def close(self):
        """Cierra la aplicaci√≥n y libera recursos."""
        if hasattr(self, 'hand_detector'):
            self.hand_detector.close()


def main():
    """Punto de entrada de la mini-app."""
    try:
        app = AirDrawClassifier()
        app.run()
    except KeyboardInterrupt:
        print("\n‚ö† Interrupci√≥n detectada")
    except Exception as e:
        print(f"‚ùå Error en la mini-app: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()